{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "import csv\n",
    "import operator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression # load the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sentiment.csv\",encoding='ISO-8859-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "1  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "2  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    8493\n",
       "Positive    2236\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert labels into a machine readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_y = ['Negative','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(train_class_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_ = le.transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['Positive','Negative','Positive']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to clean the text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def CleanText(raw_comment):\n",
    "    # 1. lower case\n",
    "    new_comment = raw_comment.lower()\n",
    "    # 2. remove punctuation\n",
    "    new_comment = re.sub(r\"[^\\w\\s]\", \"\", new_comment)\n",
    "    \n",
    "      #add something new\n",
    "    #new_comment = new_comment.replace('\\n','').strip()\n",
    "    #new_comment = new_comment.replace(u'\\u2018',\"'\").replace(u'\\u2019',\"'\") \n",
    "    #new_comment = new_comment.replace('n\\'t',' not')\n",
    "    #new_comment = new_comment.replace('RT','')\n",
    "    #new_comment = re.sub(r\"^.*http.*$\", '', new_comment)\n",
    "    #new_comment = re.sub(r'[^\\x00-\\x7F]+','', new_comment)\n",
    "    #new_comment = new_comment.replace('gop','')\n",
    "    #new_comment = new_comment.replace('debate','')\n",
    "    #new_comment = new_comment.replace('gopdeb','')\n",
    "    #new_comment = new_comment.replace('gopdebate','')\n",
    "    #new_comment = new_comment.replace('gopdebates','')\n",
    "    #new_comment = new_comment.replace('fox','')\n",
    "    #new_comment = new_comment.replace('news','')\n",
    "    #new_comment = new_comment.replace('foxnew','')\n",
    "    #new_comment = new_comment.replace('foxnes','')\n",
    "    #new_comment = new_comment.replace('amp','')\n",
    "    \n",
    "    \n",
    "    return new_comment\n",
    "\n",
    "#Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "#Stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'] = df['text'].apply(CleanText)\n",
    "#df['text'] = df['text'].apply(removeStopWords)\n",
    "#df['text'] = df['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "1  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "2  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size = .10, random_state=7)\n",
    "#xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "train_y = le.transform(train['sentiment'])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(CleanText)\n",
    "train['text'] = train['text'].apply(removeStopWords)\n",
    "train['text'] = train['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing using bag of words - UNI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, 12533)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107171"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(X_train_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['07',\n",
       " '0iiiiiii0_girl',\n",
       " '10',\n",
       " '100',\n",
       " '10000',\n",
       " '100000',\n",
       " '10000x',\n",
       " '1000s',\n",
       " '100kyr',\n",
       " '100s',\n",
       " '1015',\n",
       " '106',\n",
       " '10k',\n",
       " '11',\n",
       " '1100',\n",
       " '11000',\n",
       " '1111',\n",
       " '116',\n",
       " '11th',\n",
       " '12',\n",
       " '1216bj',\n",
       " '13',\n",
       " '130',\n",
       " '13m',\n",
       " '14',\n",
       " '140charact',\n",
       " '143',\n",
       " '14th',\n",
       " '15',\n",
       " '1525',\n",
       " '15min',\n",
       " '15yo',\n",
       " '16',\n",
       " '160',\n",
       " '16m',\n",
       " '17',\n",
       " '170',\n",
       " '176b',\n",
       " '18',\n",
       " '18000',\n",
       " '1800s',\n",
       " '1828',\n",
       " '187k',\n",
       " '189',\n",
       " '19',\n",
       " '1954',\n",
       " '1955',\n",
       " '1960s',\n",
       " '1965',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1996',\n",
       " '1997',\n",
       " '19b',\n",
       " '19h19',\n",
       " '19million',\n",
       " '1aâstopiran',\n",
       " '1brian',\n",
       " '1catherinesiena',\n",
       " '1hr',\n",
       " '1m',\n",
       " '1marchella',\n",
       " '1marcorubio',\n",
       " '1on1',\n",
       " '1st',\n",
       " '1stplace',\n",
       " '1what',\n",
       " '20',\n",
       " '2000',\n",
       " '200000',\n",
       " '2000s',\n",
       " '2001',\n",
       " '20012009',\n",
       " '2003',\n",
       " '2004',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2009â',\n",
       " '2010',\n",
       " '201112',\n",
       " '2012',\n",
       " '2013',\n",
       " '2013_tiffani',\n",
       " '2015',\n",
       " '2016',\n",
       " '2016elect',\n",
       " '206',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '213',\n",
       " '215000',\n",
       " '21million',\n",
       " '21st',\n",
       " '21th',\n",
       " '22',\n",
       " '229b',\n",
       " '22aday',\n",
       " '22nd',\n",
       " '23',\n",
       " '23115',\n",
       " '24000',\n",
       " '247',\n",
       " '24b',\n",
       " '24yearold',\n",
       " '250',\n",
       " '25k',\n",
       " '263remov',\n",
       " '27',\n",
       " '29',\n",
       " '2a',\n",
       " '2afight',\n",
       " '2brian',\n",
       " '2carlyfiorina',\n",
       " '2d',\n",
       " '2destroy',\n",
       " '2dopeantibhvr',\n",
       " '2hr',\n",
       " '2ignor',\n",
       " '2jeb',\n",
       " '2min',\n",
       " '2minut',\n",
       " '2nd',\n",
       " '2ndlook',\n",
       " '2night',\n",
       " '2nit',\n",
       " '2noam',\n",
       " '2pick',\n",
       " '2show',\n",
       " '2straighten',\n",
       " '2take',\n",
       " '2the',\n",
       " '2them',\n",
       " '2tuff15',\n",
       " '2x',\n",
       " '30',\n",
       " '3000',\n",
       " '30000',\n",
       " '300lbs',\n",
       " '30day',\n",
       " '31',\n",
       " '315',\n",
       " '317',\n",
       " '32',\n",
       " '33000',\n",
       " '34',\n",
       " '34pm',\n",
       " '35',\n",
       " '350000',\n",
       " '350m',\n",
       " '352am',\n",
       " '360vodka',\n",
       " '37',\n",
       " '375',\n",
       " '3am',\n",
       " '3chicspolitico',\n",
       " '3d',\n",
       " '3hrs',\n",
       " '3k',\n",
       " '3m3',\n",
       " '3pm',\n",
       " '3rand',\n",
       " '3rd',\n",
       " '3tedcruz',\n",
       " '3x',\n",
       " '3yearold',\n",
       " '3â',\n",
       " '40',\n",
       " '400',\n",
       " '40000',\n",
       " '400k',\n",
       " '40s',\n",
       " '412v70',\n",
       " '419in703',\n",
       " '43',\n",
       " '430',\n",
       " '44',\n",
       " '45',\n",
       " '45t',\n",
       " '46',\n",
       " '467',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '4a',\n",
       " '4apostl',\n",
       " '4billlewi',\n",
       " '4gen234',\n",
       " '4realbencarson',\n",
       " '4th',\n",
       " '4thamend',\n",
       " '4what',\n",
       " '4yr',\n",
       " '50',\n",
       " '500',\n",
       " '500pm',\n",
       " '501c3',\n",
       " '50b',\n",
       " '50k',\n",
       " '50th',\n",
       " '510',\n",
       " '52',\n",
       " '53',\n",
       " '533',\n",
       " '535m',\n",
       " '56000',\n",
       " '56209000',\n",
       " '575000',\n",
       " '59',\n",
       " '5ricksantorum',\n",
       " '5th',\n",
       " '5vote',\n",
       " '5yearold',\n",
       " '60',\n",
       " '60min',\n",
       " '60s',\n",
       " '62valdovino',\n",
       " '65',\n",
       " '67',\n",
       " '68',\n",
       " '685',\n",
       " '69ing',\n",
       " '6lb',\n",
       " '6million',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '700m',\n",
       " '73m',\n",
       " '745',\n",
       " '750',\n",
       " '757',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '800b',\n",
       " '808s_n_cupcak',\n",
       " '80k',\n",
       " '80s',\n",
       " '81',\n",
       " '816am',\n",
       " '816amâ',\n",
       " '87',\n",
       " '8pm',\n",
       " '8yearold',\n",
       " '90',\n",
       " '900',\n",
       " '900000',\n",
       " '90s',\n",
       " '91011',\n",
       " '911',\n",
       " '911woth',\n",
       " '92',\n",
       " '93wibc',\n",
       " '96',\n",
       " '96sun',\n",
       " '99',\n",
       " '9m9',\n",
       " '9pm',\n",
       " '_alexandragold_',\n",
       " '_andybry',\n",
       " '_brothag',\n",
       " '_darling_nikki',\n",
       " '_edman_',\n",
       " '_hankrearden',\n",
       " '_herking__',\n",
       " '_hetrick',\n",
       " '_holly_rene',\n",
       " '_kingmalcolm',\n",
       " '_mattybswag',\n",
       " '_ms_bee',\n",
       " '_musicluvr',\n",
       " '_natedrak',\n",
       " '_rightchick',\n",
       " '_ryanturek',\n",
       " '_sfrnc',\n",
       " '_shannonrose17_',\n",
       " 'a3rd',\n",
       " 'aa',\n",
       " 'aaaaaaaaaaaaaaand',\n",
       " 'aaaand',\n",
       " 'aaand',\n",
       " 'aandgshow',\n",
       " 'aapsonlin',\n",
       " 'aaronjacksond',\n",
       " 'abandon',\n",
       " 'abb_robertscbn',\n",
       " 'abbijacobson',\n",
       " 'abbott',\n",
       " 'abburgess95',\n",
       " 'abc',\n",
       " 'abe_munoz',\n",
       " 'abhorr',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'ablanketyblank',\n",
       " 'ableg',\n",
       " 'abloomy09',\n",
       " 'abolish',\n",
       " 'abort',\n",
       " 'abortionismurd',\n",
       " 'abortionâ',\n",
       " 'abortus',\n",
       " 'about',\n",
       " 'aboâ',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'abs_tellthetal',\n",
       " 'absofuckinglut',\n",
       " 'absolut',\n",
       " 'absurd',\n",
       " 'absurdwith',\n",
       " 'abt',\n",
       " 'aburgeraday',\n",
       " 'abus',\n",
       " 'abysm',\n",
       " 'ac',\n",
       " 'ac360',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accomplish',\n",
       " 'accomplishmentsar',\n",
       " 'accord',\n",
       " 'according2mi',\n",
       " 'account',\n",
       " 'acct',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'accus',\n",
       " 'accuâ',\n",
       " 'acerbicaxiom',\n",
       " 'achiev',\n",
       " 'ackit',\n",
       " 'acpress_tracey',\n",
       " 'acpresskram',\n",
       " 'acr',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actin',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activist',\n",
       " 'actoflov',\n",
       " 'actonclim',\n",
       " 'actor',\n",
       " 'actshow',\n",
       " 'actual',\n",
       " 'acu',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adambrownag',\n",
       " 'adamkareem',\n",
       " 'adamogdenceo',\n",
       " 'adamsflafan',\n",
       " 'adamslili',\n",
       " 'adamsmith_usa',\n",
       " 'adapt',\n",
       " 'adbridgeforth',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'address',\n",
       " 'adellenaz',\n",
       " 'adelsbergerdan',\n",
       " 'adhes',\n",
       " 'adillard4',\n",
       " 'admin',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'adobo',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adorb',\n",
       " 'adr',\n",
       " 'aduanebrown',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adventur',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advil',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'advoc',\n",
       " 'advocacybut',\n",
       " 'aebrennen',\n",
       " 'aegon',\n",
       " 'aelmor',\n",
       " 'aerosmith',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affectn',\n",
       " 'affili',\n",
       " 'affin',\n",
       " 'afford',\n",
       " 'affordablecareact',\n",
       " 'afforâ',\n",
       " 'afghanistan',\n",
       " 'aficklelover_',\n",
       " 'aflcio',\n",
       " 'afloat',\n",
       " 'afp_nh',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanacarr',\n",
       " 'africanamerican',\n",
       " 'africanamerâ',\n",
       " 'afriendinde',\n",
       " 'afrochubbz',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterparti',\n",
       " 'aftertrump',\n",
       " 'afterward',\n",
       " 'ag_conserv',\n",
       " 'again',\n",
       " 'againpalin',\n",
       " 'againstcronycap',\n",
       " 'againthat',\n",
       " 'againâ',\n",
       " 'agaiâ',\n",
       " 'age',\n",
       " 'agehi',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agerney',\n",
       " 'ageâ',\n",
       " 'aggress',\n",
       " 'aggriev',\n",
       " 'aghhh',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'agrâ',\n",
       " 'ah',\n",
       " 'ahahahahaha',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahol',\n",
       " 'ahzoov',\n",
       " 'aid',\n",
       " 'aiiamericangiri',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'ainf',\n",
       " 'ainsli',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airmen',\n",
       " 'airport',\n",
       " 'airtim',\n",
       " 'aisl',\n",
       " 'ajc4oth',\n",
       " 'aka',\n",
       " 'akhenaten15',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'al_gorelioni',\n",
       " 'alan',\n",
       " 'alasscan_',\n",
       " 'alawlaki',\n",
       " 'album',\n",
       " 'alchol',\n",
       " 'alcohol',\n",
       " 'alcoholpoison',\n",
       " 'aldon',\n",
       " 'alec',\n",
       " 'alecmapa',\n",
       " 'aleist',\n",
       " 'alert',\n",
       " 'alex_uriarte88',\n",
       " 'alexandergold',\n",
       " 'alexandersoro',\n",
       " 'alexandraheus',\n",
       " 'alexcast',\n",
       " 'alexcon',\n",
       " 'alexfromphilli',\n",
       " 'alexhalperin',\n",
       " 'alexisinnh',\n",
       " 'alexsamuelsx5',\n",
       " 'alexwagn',\n",
       " 'algor',\n",
       " 'ali',\n",
       " 'ali_davi',\n",
       " 'alicelinahan',\n",
       " 'alicewhunt',\n",
       " 'alien',\n",
       " 'alik',\n",
       " 'alikat747',\n",
       " 'alilihay',\n",
       " 'alinski',\n",
       " 'aliseeeeb',\n",
       " 'alishagrauso',\n",
       " 'alison_rambl',\n",
       " 'alissalyn14',\n",
       " 'alist',\n",
       " 'alittlesidestep',\n",
       " 'alittlestat',\n",
       " 'aliv',\n",
       " 'all',\n",
       " 'allahpundit',\n",
       " 'alldigitocraci',\n",
       " 'alleg',\n",
       " 'allegi',\n",
       " 'allegrakirkland',\n",
       " 'allen_bet',\n",
       " 'allenwestrepub',\n",
       " 'alli',\n",
       " 'allianc',\n",
       " 'alliebidwel',\n",
       " 'allierenison',\n",
       " 'allin',\n",
       " 'alllivesmatt',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'allstat',\n",
       " 'allthingsflynn',\n",
       " 'alltim',\n",
       " 'ally_eddi',\n",
       " 'allâ',\n",
       " 'almightygod',\n",
       " 'almost',\n",
       " 'alocalgyro',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alongsidewild',\n",
       " 'alot',\n",
       " 'alpal_23',\n",
       " 'alpha',\n",
       " 'alreadi',\n",
       " 'alreadyglad',\n",
       " 'alreadygoogl',\n",
       " 'also',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'alway',\n",
       " 'alyonamink',\n",
       " 'alyssalafag',\n",
       " 'alyssaphuck',\n",
       " 'alz',\n",
       " 'amandaclockwood',\n",
       " 'amandaemcgowan',\n",
       " 'amandagutterman',\n",
       " 'amandajbutt',\n",
       " 'amandawil',\n",
       " 'amaraconda',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amayanabo_cov',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'amberjphillip',\n",
       " 'ambertoz',\n",
       " 'ambervanbe',\n",
       " 'ambitiouspaul',\n",
       " 'ambival',\n",
       " 'ambjohnbolton',\n",
       " 'ambush',\n",
       " 'amc',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'america4israel',\n",
       " 'americameow',\n",
       " 'american',\n",
       " 'american_mirror',\n",
       " 'americangopdeb',\n",
       " 'americanidol',\n",
       " 'americans4am',\n",
       " 'americansunit',\n",
       " 'americanvot',\n",
       " 'americaonpoint',\n",
       " 'americasgotfail',\n",
       " 'americasgottal',\n",
       " 'americasmostcorruptgovernor',\n",
       " 'americaâ',\n",
       " 'americnhumanist',\n",
       " 'americâ',\n",
       " 'amerâ',\n",
       " 'amewait',\n",
       " 'ami',\n",
       " 'aminespn',\n",
       " 'amiramitch',\n",
       " 'amiranda',\n",
       " 'amirit',\n",
       " 'amnakhalid',\n",
       " 'amnesti',\n",
       " 'amok',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'ampaft',\n",
       " 'ampchristi',\n",
       " 'ampgo',\n",
       " 'amphetamine47',\n",
       " 'ampor',\n",
       " 'ampplan',\n",
       " 'amprog',\n",
       " 'ampthem',\n",
       " 'amus',\n",
       " 'amyjofox',\n",
       " 'amylazscdc',\n",
       " 'amymek',\n",
       " 'analog',\n",
       " 'analys',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'anarousedwoman',\n",
       " 'ancapkati',\n",
       " 'ancestri',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'andandgod',\n",
       " 'anddd',\n",
       " 'anddonaldtrump',\n",
       " 'anderson',\n",
       " 'andersoncoop',\n",
       " 'andor',\n",
       " 'andrea',\n",
       " 'andreagrim',\n",
       " 'andrealeon',\n",
       " 'andreatantaro',\n",
       " 'andrejuwaan',\n",
       " 'andrew_marcinko',\n",
       " 'andrewbreitbart',\n",
       " 'andrewcryer1',\n",
       " 'andrewklavan',\n",
       " 'andrewwmullin',\n",
       " 'andwon',\n",
       " 'andykhouri',\n",
       " 'anecdot',\n",
       " 'anergo_teach',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angela_ry',\n",
       " 'angelahaysmoor',\n",
       " 'anger',\n",
       " 'angie_bril',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'angrier',\n",
       " 'angrili',\n",
       " 'angryblackladi',\n",
       " 'angrytweet',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'animalsâ',\n",
       " 'anisaliban',\n",
       " 'anjemchoudari',\n",
       " 'ankl',\n",
       " 'ann',\n",
       " 'anncoult',\n",
       " 'annebayefski',\n",
       " 'annemariew',\n",
       " 'annieslisttx',\n",
       " 'annietiqu',\n",
       " 'annis',\n",
       " 'anniv',\n",
       " 'anniversari',\n",
       " 'annleari',\n",
       " 'annmariebrok',\n",
       " 'annot',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annoyinggopdeb',\n",
       " 'annrichard',\n",
       " 'annstokes55',\n",
       " 'anntbush',\n",
       " 'anntelna',\n",
       " 'annual',\n",
       " 'anoint',\n",
       " 'anomaly100',\n",
       " 'anonym',\n",
       " 'anoth',\n",
       " 'anowrt',\n",
       " 'ansonmount',\n",
       " 'answer',\n",
       " 'answersâ',\n",
       " 'antacid',\n",
       " 'antarianrani',\n",
       " 'anthonycumia',\n",
       " 'anthonymarlow',\n",
       " 'anti',\n",
       " 'anti2a',\n",
       " 'antiabort',\n",
       " 'antichoic',\n",
       " 'anticip',\n",
       " 'antiestablish',\n",
       " 'antifragil',\n",
       " 'antigay',\n",
       " 'antigovern',\n",
       " 'antiimmigr',\n",
       " 'antiintellectu',\n",
       " 'antiisil',\n",
       " 'antilgbt',\n",
       " 'antipolit',\n",
       " 'antisoci',\n",
       " 'antiunion',\n",
       " 'antiwhit',\n",
       " 'antiwoman',\n",
       " 'antiâ',\n",
       " 'antonio',\n",
       " 'anwar',\n",
       " 'any1',\n",
       " 'anybodi',\n",
       " 'anyhoot2',\n",
       " 'anymor',\n",
       " 'anymâ',\n",
       " 'anyon',\n",
       " 'anyonebut',\n",
       " 'anyonebuthillari',\n",
       " 'anyonegopdeb',\n",
       " 'anyoâ',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'anâ',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apathycas',\n",
       " 'apechtold',\n",
       " 'apipwhisper',\n",
       " 'apocalyps',\n",
       " 'apolog',\n",
       " 'apologist',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appeas',\n",
       " 'appetit',\n",
       " 'appl',\n",
       " 'applaud',\n",
       " 'applaus',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'applâ',\n",
       " 'appoint',\n",
       " 'appointe',\n",
       " 'appreci',\n",
       " 'apprentic',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'appt',\n",
       " 'appâ',\n",
       " 'aprildryan',\n",
       " 'apropo',\n",
       " 'aprx',\n",
       " 'apstat',\n",
       " 'aptitud',\n",
       " 'apunkfemm',\n",
       " 'aquaman',\n",
       " 'ar15',\n",
       " 'arbitrari',\n",
       " 'arc',\n",
       " 'archaic',\n",
       " 'archon',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'arenât',\n",
       " 'areyoukiddingmewiththi',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'ariberman',\n",
       " 'aridavidusa',\n",
       " 'aris',\n",
       " 'ariscott',\n",
       " 'aristocrat',\n",
       " 'ark',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'aros',\n",
       " 'around',\n",
       " 'aroww333',\n",
       " 'arrang',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrog',\n",
       " 'arrogantsnarki',\n",
       " 'ars',\n",
       " 'arsamandica',\n",
       " 'arseniohal',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'arthura_p',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'artiswarusa',\n",
       " 'arâ',\n",
       " 'ash',\n",
       " 'asham',\n",
       " 'ashleyhblak',\n",
       " 'ashton',\n",
       " 'ashvsevildead',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'asimhaneef',\n",
       " 'asinin',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assault',\n",
       " 'assaultweapon',\n",
       " 'assclown',\n",
       " 'assembl',\n",
       " 'asses',\n",
       " 'assess',\n",
       " 'asset',\n",
       " 'asshat',\n",
       " 'asshatteri',\n",
       " 'asshol',\n",
       " 'assholeofday',\n",
       " 'assholeri',\n",
       " 'assholeâ',\n",
       " 'assimil',\n",
       " 'assist',\n",
       " 'asskiss',\n",
       " 'assum',\n",
       " 'assur',\n",
       " 'assâ',\n",
       " 'astonish',\n",
       " 'astorix23',\n",
       " 'astound',\n",
       " 'astrokati',\n",
       " 'asund',\n",
       " 'asylum',\n",
       " 'atdleft',\n",
       " 'ate',\n",
       " 'atheist',\n",
       " 'atheist_tweet',\n",
       " 'athena',\n",
       " 'athlet',\n",
       " 'atjonford80',\n",
       " 'atlant',\n",
       " 'atlanticc',\n",
       " 'atlcav',\n",
       " 'atom',\n",
       " 'atrisk',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attackdog',\n",
       " 'attackedðª',\n",
       " 'attackng',\n",
       " 'attacâ',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attentionwhich',\n",
       " 'atti',\n",
       " 'atticalock',\n",
       " 'attila',\n",
       " 'attitud',\n",
       " 'attn',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'atypicalart',\n",
       " 'aubreysitterson',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'auditorium',\n",
       " 'auditthemedia',\n",
       " 'audreycnn',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auntcol54',\n",
       " 'aurabogado',\n",
       " 'auspol',\n",
       " 'austin',\n",
       " 'australian',\n",
       " 'authent',\n",
       " 'author',\n",
       " 'authorkimberley',\n",
       " 'autie_liz21',\n",
       " 'autism',\n",
       " 'automat',\n",
       " 'avabeata',\n",
       " 'avail',\n",
       " 'aveng',\n",
       " 'aventadorâ',\n",
       " 'averag',\n",
       " 'averagechirp',\n",
       " 'averykayla',\n",
       " 'avian',\n",
       " 'aviat',\n",
       " 'avidheath',\n",
       " 'avn',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awak',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awepra',\n",
       " 'awesom',\n",
       " 'awkord',\n",
       " 'awkward',\n",
       " 'awright',\n",
       " 'aww',\n",
       " 'awwwww',\n",
       " 'awyattman88',\n",
       " 'awâ',\n",
       " 'axe',\n",
       " 'axi',\n",
       " 'ayeedxnni',\n",
       " 'azpatriot01',\n",
       " 'azz',\n",
       " 'aâ',\n",
       " 'b140_tweet',\n",
       " 'b140tweet',\n",
       " 'b4',\n",
       " 'b52',\n",
       " 'b52s',\n",
       " 'ba',\n",
       " 'baaaaack',\n",
       " 'baaaack',\n",
       " 'babara',\n",
       " 'babi',\n",
       " 'babycurtiselli',\n",
       " 'bachelorett',\n",
       " 'bacheloretteabc',\n",
       " 'bachmannsbrain',\n",
       " 'back',\n",
       " 'backassward',\n",
       " 'backer',\n",
       " 'backfir',\n",
       " 'background',\n",
       " 'backgrounâ',\n",
       " 'backlash',\n",
       " 'backrupt',\n",
       " 'backward',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bacâ',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badassbiden',\n",
       " 'badassteachersa',\n",
       " 'badassteacherâ',\n",
       " 'badblood',\n",
       " 'baddi',\n",
       " 'badg',\n",
       " 'badger',\n",
       " 'badgersban',\n",
       " 'badirand',\n",
       " 'badsorri',\n",
       " 'bae',\n",
       " 'baffl',\n",
       " 'bagger',\n",
       " 'bahahaaaaaaharwsurfergirl',\n",
       " 'baier',\n",
       " 'bailey',\n",
       " 'bailofright',\n",
       " 'bait',\n",
       " 'balanc',\n",
       " 'balconi',\n",
       " 'balderdash',\n",
       " 'ball',\n",
       " 'ballcap',\n",
       " 'baller',\n",
       " 'balloon',\n",
       " 'baltimor',\n",
       " 'bam',\n",
       " 'bamasever',\n",
       " 'ban',\n",
       " 'banal',\n",
       " 'band',\n",
       " 'bandwagon',\n",
       " 'bang',\n",
       " 'banish',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bankrupt',\n",
       " 'bankruptci',\n",
       " 'bannerit',\n",
       " 'banquet',\n",
       " 'banshe',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barackobama',\n",
       " 'barbar',\n",
       " 'barbarabox',\n",
       " 'barbarian',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for BOW + UNI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(X_train_counts,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)\n",
    "test_x = count_vect.transform(test['cleantxt'])\n",
    "test_x_array = test_x.toarray()\n",
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(test_x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8471575023299162"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[812,  41],\n",
       "       [123,  97]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions,labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('uniwrong.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]!=test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 1:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','positive'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 0: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','negtive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('uniright.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]==test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 0:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','negative'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 1: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','positive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing using bag of words - UNI + BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, 61807)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207490"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(X_train_counts.toarray()) ## Just checking for non zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['07',\n",
       " '07 fun',\n",
       " '0iiiiiii0_girl',\n",
       " '0iiiiiii0_girl take',\n",
       " '10',\n",
       " '10 2001',\n",
       " '10 angri',\n",
       " '10 appt',\n",
       " '10 best',\n",
       " '10 billion',\n",
       " '10 candid',\n",
       " '10 carlyfiorina',\n",
       " '10 contend',\n",
       " '10 couldnt',\n",
       " '10 cringeworthi',\n",
       " '10 donat',\n",
       " '10 dread',\n",
       " '10 gotten',\n",
       " '10 gov',\n",
       " '10 guy',\n",
       " '10 horsemen',\n",
       " '10 httptconp0vngnotx',\n",
       " '10 httptcovxszukmivb',\n",
       " '10 httâ',\n",
       " '10 insan',\n",
       " '10 man',\n",
       " '10 mani',\n",
       " '10 men',\n",
       " '10 mil',\n",
       " '10 million',\n",
       " '10 millionair',\n",
       " '10 min',\n",
       " '10 moment',\n",
       " '10 mudsling',\n",
       " '10 peopl',\n",
       " '10 sec',\n",
       " '10 straight',\n",
       " '10 wealthi',\n",
       " '10 white',\n",
       " '10 women',\n",
       " '10 year',\n",
       " '10 yrs',\n",
       " '100',\n",
       " '100 almost',\n",
       " '100 even',\n",
       " '100 hilari',\n",
       " '100 min',\n",
       " '100 minut',\n",
       " '100 rate',\n",
       " '100 sergey',\n",
       " '100 support',\n",
       " '100 sure',\n",
       " '100 vote',\n",
       " '10000',\n",
       " '10000 follow',\n",
       " '100000',\n",
       " '100000 1996',\n",
       " '100000 protest',\n",
       " '10000x',\n",
       " '10000x better',\n",
       " '1000s',\n",
       " '1000s job',\n",
       " '1000s union',\n",
       " '100kyr',\n",
       " '100kyr consid',\n",
       " '100s',\n",
       " '100s 1000s',\n",
       " '1015',\n",
       " '1015 carson',\n",
       " '106',\n",
       " '106 billion',\n",
       " '10k',\n",
       " '10k new',\n",
       " '11',\n",
       " '11 gopdeb',\n",
       " '11 illeg',\n",
       " '11 minut',\n",
       " '11 year',\n",
       " '1100',\n",
       " '1100 candid',\n",
       " '11000',\n",
       " '11000 marcorubio',\n",
       " '1111',\n",
       " '1111 makeawish',\n",
       " '116',\n",
       " '116 minut',\n",
       " '11th',\n",
       " '11th gopdeb',\n",
       " '12',\n",
       " '12 angri',\n",
       " '12 hour',\n",
       " '12 time',\n",
       " '12 trump',\n",
       " '12 year',\n",
       " '1216bj',\n",
       " '1216bj gopdeb',\n",
       " '13',\n",
       " '13 gop',\n",
       " '13 minut',\n",
       " '130',\n",
       " '130 raceâ',\n",
       " '13m',\n",
       " '13m job',\n",
       " '14',\n",
       " '14 focus',\n",
       " '14 mention',\n",
       " '14 month',\n",
       " '14 news',\n",
       " '14 peopl',\n",
       " '140charact',\n",
       " '140charact twitter',\n",
       " '143',\n",
       " '143 show',\n",
       " '14th',\n",
       " '14th amend',\n",
       " '15',\n",
       " '15 34',\n",
       " '15 amnesti',\n",
       " '15 back',\n",
       " '15 gopdeb',\n",
       " '15 min',\n",
       " '15 minut',\n",
       " '15 second',\n",
       " '15 xanax',\n",
       " '15 yr',\n",
       " '1525',\n",
       " '1525 bingo',\n",
       " '15min',\n",
       " '15min say',\n",
       " '15yo',\n",
       " '15yo self',\n",
       " '16',\n",
       " '16 candid',\n",
       " '16 candidatesclear',\n",
       " '16 funniest',\n",
       " '16 market',\n",
       " '16 mâ',\n",
       " '16 peopl',\n",
       " '16 radic',\n",
       " '16 share',\n",
       " '16 time',\n",
       " '16 unit',\n",
       " '16 us',\n",
       " '160',\n",
       " '160 household',\n",
       " '160 nationwid',\n",
       " '160 overnight',\n",
       " '16m',\n",
       " '16m fl',\n",
       " '17',\n",
       " '17 candid',\n",
       " '17 candidaâ',\n",
       " '17 classi',\n",
       " '17 funniest',\n",
       " '17 million',\n",
       " '17 sure',\n",
       " '17 way',\n",
       " '17 year',\n",
       " '170',\n",
       " '170 ill',\n",
       " '176b',\n",
       " '176b deficit',\n",
       " '18',\n",
       " '18 state',\n",
       " '18000',\n",
       " '18000 peopl',\n",
       " '1800s',\n",
       " '1800s gopdeb',\n",
       " '1828',\n",
       " '1828 debat',\n",
       " '187k',\n",
       " '187k realdonaldtrump',\n",
       " '189',\n",
       " '189 million',\n",
       " '19',\n",
       " '19 mention',\n",
       " '19 trillion',\n",
       " '1954',\n",
       " '1955',\n",
       " '1955 gopdeb',\n",
       " '1960s',\n",
       " '1960s gopdeb',\n",
       " '1965',\n",
       " '1965 immigr',\n",
       " '1965 wtf',\n",
       " '1980',\n",
       " '1980 elect',\n",
       " '1980 worst',\n",
       " '1980s',\n",
       " '1980s gopdeb',\n",
       " '1996',\n",
       " '1996 2013',\n",
       " '1997',\n",
       " '1997 tcot',\n",
       " '19b',\n",
       " '19b includ',\n",
       " '19h19',\n",
       " '19h19 hour',\n",
       " '19million',\n",
       " '19million job',\n",
       " '1aâstopiran',\n",
       " '1aâstopiran gopdebateâºhttptcozwmstjjh16â19t',\n",
       " '1brian',\n",
       " '1brian kendracp',\n",
       " '1catherinesiena',\n",
       " '1catherinesiena glennbeck',\n",
       " '1hr',\n",
       " '1hr canât',\n",
       " '1m',\n",
       " '1m minut',\n",
       " '1m run',\n",
       " '1marchella',\n",
       " '1marchella straight',\n",
       " '1marcorubio',\n",
       " '1marcorubio 2carlyfiorina',\n",
       " '1on1',\n",
       " '1on1 chrischristi',\n",
       " '1on1 debat',\n",
       " '1st',\n",
       " '1st 2min',\n",
       " '1st 90s',\n",
       " '1st amend',\n",
       " '1st answer',\n",
       " '1st cruz2016',\n",
       " '1st day',\n",
       " '1st debat',\n",
       " '1st donald',\n",
       " '1st episod',\n",
       " '1st gop',\n",
       " '1st gopdeb',\n",
       " '1st gopdebateencourag',\n",
       " '1st one',\n",
       " '1st place',\n",
       " '1st question',\n",
       " '1st round',\n",
       " '1st term',\n",
       " '1stplace',\n",
       " '1stplace trump',\n",
       " '1what',\n",
       " '1what walker',\n",
       " '20',\n",
       " '20 minut',\n",
       " '20 question',\n",
       " '20 sec',\n",
       " '20 week',\n",
       " '20 year',\n",
       " '2000',\n",
       " '2000 amp',\n",
       " '2000 elecâ',\n",
       " '2000 media',\n",
       " '200000',\n",
       " '200000 vote',\n",
       " '2000s',\n",
       " '2000s billionair',\n",
       " '2001',\n",
       " '2001 actual',\n",
       " '2001 gopdeb',\n",
       " '20012009',\n",
       " '20012009 donald',\n",
       " '2003',\n",
       " '2003 gopdeb',\n",
       " '2004',\n",
       " '2004 gopdeb',\n",
       " '2004 invas',\n",
       " '2007',\n",
       " '2007 pree',\n",
       " '2008',\n",
       " '2008 amp',\n",
       " '2009',\n",
       " '2009 day',\n",
       " '2009â',\n",
       " '2009â ââ',\n",
       " '2010',\n",
       " '2010 gopdeb',\n",
       " '201112',\n",
       " '201112 53',\n",
       " '201112 httptco4ih7btyeaz',\n",
       " '2012',\n",
       " '2012 afraid',\n",
       " '2012 again',\n",
       " '2012 chide',\n",
       " '2012 cnn',\n",
       " '2012 elect',\n",
       " '2012 gop',\n",
       " '2012 httptcohtwqozlegb',\n",
       " '2012 talk',\n",
       " '2013',\n",
       " '2013 gopdeb',\n",
       " '2013 httptcohxkzuee2uf',\n",
       " '2013 kasich',\n",
       " '2013 said',\n",
       " '2013_tiffani',\n",
       " '2013_tiffani rubio',\n",
       " '2015',\n",
       " '2015 amp',\n",
       " '2015 cant',\n",
       " '2015 doesnt',\n",
       " '2015 edit',\n",
       " '2015 gop',\n",
       " '2015 gopdeb',\n",
       " '2015 parodi',\n",
       " '2015 still',\n",
       " '2015 thank',\n",
       " '2016',\n",
       " '2016 aâ',\n",
       " '2016 bender',\n",
       " '2016 berni',\n",
       " '2016 c2',\n",
       " '2016 candid',\n",
       " '2016 consid',\n",
       " '2016 cruz',\n",
       " '2016 cruztovictori',\n",
       " '2016 gop',\n",
       " '2016 gopdeb',\n",
       " '2016 httptco5rfh5zbnpm',\n",
       " '2016 httptcomhtd8ypwlb',\n",
       " '2016 httptcoq7bhknxwi',\n",
       " '2016 httptcowoqo4vly9p',\n",
       " '2016 johnkasich',\n",
       " '2016 liar',\n",
       " '2016 megynkelli',\n",
       " '2016 need',\n",
       " '2016 news',\n",
       " '2016 platform',\n",
       " '2016 predict',\n",
       " '2016 presidenti',\n",
       " '2016 primari',\n",
       " '2016 republican',\n",
       " '2016 seem',\n",
       " '2016 teamdrbencarson',\n",
       " '2016 time',\n",
       " '2016 woman',\n",
       " '2016elect',\n",
       " '2016elect gopdeb',\n",
       " '2016elect toomanytodraw',\n",
       " '206',\n",
       " '206 sherrod_smal',\n",
       " '20th',\n",
       " '20th centuri',\n",
       " '20x',\n",
       " '20x like',\n",
       " '21',\n",
       " '21 peopl',\n",
       " '213',\n",
       " '213 gopdeb',\n",
       " '215000',\n",
       " '215000 job',\n",
       " '21million',\n",
       " '21million httptcoltvjngxob',\n",
       " '21st',\n",
       " '21st centuri',\n",
       " '21th',\n",
       " '21th centuri',\n",
       " '22',\n",
       " '22 declin',\n",
       " '22 like',\n",
       " '229b',\n",
       " '229b annual',\n",
       " '22aday',\n",
       " '22aday empti',\n",
       " '22nd',\n",
       " '22nd amend',\n",
       " '23',\n",
       " '23 death',\n",
       " '23115',\n",
       " '23115 cruz',\n",
       " '24000',\n",
       " '24000 vs',\n",
       " '247',\n",
       " '247 gopdeb',\n",
       " '247 im',\n",
       " '24b',\n",
       " '24b shut',\n",
       " '24yearold',\n",
       " '24yearold black',\n",
       " '250',\n",
       " '250 rts',\n",
       " '25k',\n",
       " '25k realdonaldtrump',\n",
       " '263remov',\n",
       " '263remov gopdeb',\n",
       " '27',\n",
       " '27 epic',\n",
       " '27 second',\n",
       " '27 time',\n",
       " '29',\n",
       " '29 rts',\n",
       " '2a',\n",
       " '2a ok',\n",
       " '2afight',\n",
       " '2afight jeb',\n",
       " '2afight trump',\n",
       " '2brian',\n",
       " '2brian fair',\n",
       " '2carlyfiorina',\n",
       " '2carlyfiorina 3tedcruz',\n",
       " '2d',\n",
       " '2d white',\n",
       " '2destroy',\n",
       " '2destroy happen',\n",
       " '2dopeantibhvr',\n",
       " '2dopeantibhvr want',\n",
       " '2hr',\n",
       " '2hr debat',\n",
       " '2ignor',\n",
       " '2ignor fact',\n",
       " '2jeb',\n",
       " '2jeb bush',\n",
       " '2min',\n",
       " '2min 2hr',\n",
       " '2min gopdeb',\n",
       " '2minut',\n",
       " '2minut routin',\n",
       " '2nd',\n",
       " '2nd amend',\n",
       " '2nd debat',\n",
       " '2nd favorit',\n",
       " '2nd gop',\n",
       " '2nd pack',\n",
       " '2nd place',\n",
       " '2nd round',\n",
       " '2nd string',\n",
       " '2nd worst',\n",
       " '2ndlook',\n",
       " '2ndlook gopdeb',\n",
       " '2night',\n",
       " '2night gameon',\n",
       " '2night imwithhuck',\n",
       " '2nit',\n",
       " '2nit qampa',\n",
       " '2noam',\n",
       " '2noam oh',\n",
       " '2noam sensand',\n",
       " '2noam well',\n",
       " '2pick',\n",
       " '2pick next',\n",
       " '2show',\n",
       " '2show realdonaldtrump',\n",
       " '2straighten',\n",
       " '2straighten posit',\n",
       " '2take',\n",
       " '2take tri',\n",
       " '2the',\n",
       " '2the kochbroth',\n",
       " '2them',\n",
       " '2them talkin',\n",
       " '2tuff15',\n",
       " '2tuff15 dont',\n",
       " '2x',\n",
       " '2x amount',\n",
       " '2x old',\n",
       " '30',\n",
       " '30 minut',\n",
       " '30 rock',\n",
       " '30 second',\n",
       " '30 speak',\n",
       " '30 yrs',\n",
       " '3000',\n",
       " '3000 lightyear',\n",
       " '30000',\n",
       " '30000 worker',\n",
       " '300lbs',\n",
       " '300lbs chang',\n",
       " '30day',\n",
       " '30day potd',\n",
       " '31',\n",
       " '31 airtim',\n",
       " '31 minut',\n",
       " '31 total',\n",
       " '315',\n",
       " '315 hr',\n",
       " '317',\n",
       " '317 time',\n",
       " '32',\n",
       " '32 air',\n",
       " '32 gopdeb',\n",
       " '32 time',\n",
       " '33000',\n",
       " '33000 year',\n",
       " '34',\n",
       " '34 like',\n",
       " '34 trump',\n",
       " '34pm',\n",
       " '34pm johnfugelsang',\n",
       " '35',\n",
       " '35 gopdeb',\n",
       " '35 past',\n",
       " '350000',\n",
       " '350000 new',\n",
       " '350m',\n",
       " '350m must',\n",
       " '352am',\n",
       " '352am fine',\n",
       " '360vodka',\n",
       " '360vodka patriot',\n",
       " '37',\n",
       " '37 time',\n",
       " '375',\n",
       " '375 trump',\n",
       " '3am',\n",
       " '3am tweet',\n",
       " '3chicspolitico',\n",
       " '3chicspolitico donald',\n",
       " '3chicspolitico trump',\n",
       " '3d',\n",
       " '3d chess',\n",
       " '3hrs',\n",
       " '3hrs 800',\n",
       " '3k',\n",
       " '3k american',\n",
       " '3m3',\n",
       " '3m3 minut',\n",
       " '3pm',\n",
       " '3pm gopdeb',\n",
       " '3rand',\n",
       " '3rand paul',\n",
       " '3rd',\n",
       " '3rd govt',\n",
       " '3rd grader',\n",
       " '3rd parti',\n",
       " '3rd partysometh',\n",
       " '3rd partyð',\n",
       " '3rd place',\n",
       " '3rd wed',\n",
       " '3tedcruz',\n",
       " '3tedcruz 4realbencarson',\n",
       " '3x',\n",
       " '3x daddi',\n",
       " '3x hardball_chri',\n",
       " '3x highestr',\n",
       " '3yearold',\n",
       " '3yearold thought',\n",
       " '3â',\n",
       " '3â httptcoauhlnza3ww',\n",
       " '40',\n",
       " '40 blowjobplus',\n",
       " '40 hrs',\n",
       " '40 million',\n",
       " '40 point',\n",
       " '400',\n",
       " '400 million',\n",
       " '40000',\n",
       " '40000 american',\n",
       " '400k',\n",
       " '400k student',\n",
       " '40s',\n",
       " '40s came',\n",
       " '412v70',\n",
       " '412v70 mention',\n",
       " '419in703',\n",
       " '419in703 realdonaldtrump',\n",
       " '43',\n",
       " '43 gopdeb',\n",
       " '43 minut',\n",
       " '430',\n",
       " '430 bush',\n",
       " '44',\n",
       " '44 minut',\n",
       " '44 tx',\n",
       " '45',\n",
       " '45 minut',\n",
       " '45t',\n",
       " '45t deficit',\n",
       " '46',\n",
       " '46 25k',\n",
       " '46 foxsd',\n",
       " '467',\n",
       " '467 chrischristi',\n",
       " '47',\n",
       " '47 second',\n",
       " '48',\n",
       " '48 peopl',\n",
       " '48 suspect',\n",
       " '48 year',\n",
       " '49',\n",
       " '49 realdonaldtrump',\n",
       " '4a',\n",
       " '4a chang',\n",
       " '4apostl',\n",
       " '4apostl term',\n",
       " '4billlewi',\n",
       " '4billlewi socialmedia',\n",
       " '4gen234',\n",
       " '4gen234 cruz',\n",
       " '4realbencarson',\n",
       " '4realbencarson 5ricksantorum',\n",
       " '4th',\n",
       " '4th amend',\n",
       " '4th marriag',\n",
       " '4th place',\n",
       " '4th wave',\n",
       " '4thamend',\n",
       " '4thamend suck',\n",
       " '4what',\n",
       " '4what come',\n",
       " '4yr',\n",
       " '50',\n",
       " '50 187k',\n",
       " '50 american',\n",
       " '50 amp',\n",
       " '50 cent',\n",
       " '50 sec',\n",
       " '50 time',\n",
       " '50 walker',\n",
       " '500',\n",
       " '500 gopdeb',\n",
       " '500 pm',\n",
       " '500pm',\n",
       " '501c3',\n",
       " '501c3 nonprofit',\n",
       " '50b',\n",
       " '50b infrastructur',\n",
       " '50k',\n",
       " '50k luxuri',\n",
       " '50th',\n",
       " '50th anniv',\n",
       " '50th anniversari',\n",
       " '510',\n",
       " '510 tweet',\n",
       " '52',\n",
       " '52 billion',\n",
       " '52 popul',\n",
       " '53',\n",
       " '53 201112',\n",
       " '53 rate',\n",
       " '533',\n",
       " '533 year',\n",
       " '535m',\n",
       " '535m surplus',\n",
       " '56000',\n",
       " '56000 iraqi',\n",
       " '56209000',\n",
       " '56209000 women',\n",
       " '575000',\n",
       " '575000 iraqi',\n",
       " '59',\n",
       " '59 minut',\n",
       " '5ricksantorum',\n",
       " '5th',\n",
       " '5th 14th',\n",
       " '5th amp',\n",
       " '5th place',\n",
       " '5vote',\n",
       " '5vote gopdeb',\n",
       " '5yearold',\n",
       " '5yearold kid',\n",
       " '60',\n",
       " '60 us',\n",
       " '60 year',\n",
       " '60min',\n",
       " '60min gopdeb',\n",
       " '60min kasich',\n",
       " '60s',\n",
       " '60s like',\n",
       " '62valdovino',\n",
       " '62valdovino potus',\n",
       " '65',\n",
       " '65 right',\n",
       " '67',\n",
       " '67 honorari',\n",
       " '68',\n",
       " '68 ââ',\n",
       " '685',\n",
       " '685 american',\n",
       " '69ing',\n",
       " '69ing gopdeb',\n",
       " '6lb',\n",
       " '6lb vagin',\n",
       " '6million',\n",
       " '6million peopl',\n",
       " '6th',\n",
       " '6th lead',\n",
       " '70',\n",
       " '70 new',\n",
       " '70 year',\n",
       " '700',\n",
       " '700 law',\n",
       " '700m',\n",
       " '700m wouldv',\n",
       " '73m',\n",
       " '73m instead',\n",
       " '745',\n",
       " '745 posit',\n",
       " '750',\n",
       " '750 tip',\n",
       " '757',\n",
       " '757 gopdeb',\n",
       " '7th',\n",
       " '7th place',\n",
       " '80',\n",
       " '80 peopl',\n",
       " '800',\n",
       " '800 1100',\n",
       " '800b',\n",
       " '800b unfund',\n",
       " '808s_n_cupcak',\n",
       " '808s_n_cupcak bruh',\n",
       " '80k',\n",
       " '80k boat',\n",
       " '80s',\n",
       " '80s movi',\n",
       " '80s tax',\n",
       " '81',\n",
       " '81 million',\n",
       " '816am',\n",
       " '816am gopdeb',\n",
       " '816amâ',\n",
       " '87',\n",
       " '87 gopdeb',\n",
       " '8pm',\n",
       " '8pm one',\n",
       " '8yearold',\n",
       " '8yearold boy',\n",
       " '90',\n",
       " '90 american',\n",
       " '90 camillepaglia',\n",
       " '90 day',\n",
       " '90 everyth',\n",
       " '90 minut',\n",
       " '90 second',\n",
       " '90 theyv',\n",
       " '900',\n",
       " '900 gopdeb',\n",
       " '900000',\n",
       " '900000 sig',\n",
       " '90s',\n",
       " '90s morn',\n",
       " '91011',\n",
       " '91011 enough',\n",
       " '911',\n",
       " '911 911',\n",
       " '911 attack',\n",
       " '911 big',\n",
       " '911 christi',\n",
       " '911 everi',\n",
       " '911 get',\n",
       " '911 giulianistyl',\n",
       " '911 gopdeb',\n",
       " '911 happen',\n",
       " '911 help',\n",
       " '911 mention',\n",
       " '911 minut',\n",
       " '911 nonsens',\n",
       " '911 reason',\n",
       " '911 survivor',\n",
       " '911 victim',\n",
       " '911 wasnât',\n",
       " '911woth',\n",
       " '911woth lilymaxcook',\n",
       " '92',\n",
       " '92 httptco5kuy4lveum',\n",
       " '93wibc',\n",
       " '93wibc gopdeb',\n",
       " '96',\n",
       " '96 percent',\n",
       " '96sun',\n",
       " '96sun sallykohn',\n",
       " '99',\n",
       " '99 sure',\n",
       " '99 viewer',\n",
       " '9m9',\n",
       " '9m9 minut',\n",
       " '9pm',\n",
       " '9pm est',\n",
       " '9pm gopdeb',\n",
       " '_alexandragold_',\n",
       " '_alexandragold_ root',\n",
       " '_andybry',\n",
       " '_andybry ebenjon',\n",
       " '_brothag',\n",
       " '_brothag blacklivesmatt',\n",
       " '_darling_nikki',\n",
       " '_darling_nikki rt',\n",
       " '_edman_',\n",
       " '_edman_ tweetydim',\n",
       " '_hankrearden',\n",
       " '_hankrearden john',\n",
       " '_hankrearden megynkelli',\n",
       " '_hankrearden trump',\n",
       " '_hankrearden well',\n",
       " '_herking__',\n",
       " '_herking__ entertain',\n",
       " '_hetrick',\n",
       " '_hetrick acpresskram',\n",
       " '_hetrick particular',\n",
       " '_holly_rene',\n",
       " '_holly_rene jindal',\n",
       " '_holly_rene made',\n",
       " '_kingmalcolm',\n",
       " '_kingmalcolm pro',\n",
       " '_mattybswag',\n",
       " '_mattybswag honest',\n",
       " '_ms_bee',\n",
       " '_ms_bee interestinggopdeb',\n",
       " '_musicluvr',\n",
       " '_musicluvr foxnew',\n",
       " '_natedrak',\n",
       " '_natedrak realli',\n",
       " '_rightchick',\n",
       " '_rightchick love',\n",
       " '_ryanturek',\n",
       " '_ryanturek gopdeb',\n",
       " '_sfrnc',\n",
       " '_sfrnc httptcol4wvzwwun6',\n",
       " '_shannonrose17_',\n",
       " '_shannonrose17_ deal',\n",
       " 'a3rd',\n",
       " 'a3rd parti',\n",
       " 'aa',\n",
       " 'aa chip',\n",
       " 'aa man',\n",
       " 'aaaaaaaaaaaaaaand',\n",
       " 'aaaaaaaaaaaaaaand winner',\n",
       " 'aaaand',\n",
       " 'aaaand megynfail',\n",
       " 'aaaand system',\n",
       " 'aaand',\n",
       " 'aaand question',\n",
       " 'aandgshow',\n",
       " 'aandgshow gopdeb',\n",
       " 'aandgshow great',\n",
       " 'aapsonlin',\n",
       " 'aapsonlin encourag',\n",
       " 'aaronjacksond',\n",
       " 'aaronjacksond legitim',\n",
       " 'abandon',\n",
       " 'abandon 4th',\n",
       " 'abandon alli',\n",
       " 'abandon big',\n",
       " 'abandon conserv',\n",
       " 'abandon entir',\n",
       " 'abandon immigrationreform',\n",
       " 'abandon iraq',\n",
       " 'abandon yeah',\n",
       " 'abb_robertscbn',\n",
       " 'abb_robertscbn âi',\n",
       " 'abbijacobson',\n",
       " 'abbijacobson shiiiittt',\n",
       " 'abbott',\n",
       " 'abbott gopdeb',\n",
       " 'abburgess95',\n",
       " 'abburgess95 see',\n",
       " 'abc',\n",
       " 'abc cbs',\n",
       " 'abc comedian',\n",
       " 'abc nbc',\n",
       " 'abc wntonight',\n",
       " 'abe_munoz',\n",
       " 'abe_munoz randpaul',\n",
       " 'abhorr',\n",
       " 'abhorr name',\n",
       " 'abil',\n",
       " 'abil act',\n",
       " 'abil buy',\n",
       " 'abil dig',\n",
       " 'abil govern',\n",
       " 'abil roll',\n",
       " 'abl',\n",
       " 'abl apart',\n",
       " 'abl attack',\n",
       " 'abl call',\n",
       " 'abl dismemb',\n",
       " 'abl land',\n",
       " 'abl take',\n",
       " 'abl tell',\n",
       " 'abl vote',\n",
       " 'ablanketyblank',\n",
       " 'ablanketyblank mike',\n",
       " 'ableg',\n",
       " 'ableg gopdeb',\n",
       " 'abloomy09',\n",
       " 'abloomy09 guy',\n",
       " 'abolish',\n",
       " 'abolish biolog',\n",
       " 'abolish onceandforal',\n",
       " 'abort',\n",
       " 'abort absurd',\n",
       " 'abort action',\n",
       " 'abort amp',\n",
       " 'abort ampgo',\n",
       " 'abort ban',\n",
       " 'abort contracept',\n",
       " 'abort debat',\n",
       " 'abort deserv',\n",
       " 'abort dont',\n",
       " 'abort emporium',\n",
       " 'abort even',\n",
       " 'abort evolvedâ',\n",
       " 'abort fest',\n",
       " 'abort first',\n",
       " 'abort frickin',\n",
       " 'abort friend',\n",
       " 'abort gopdeb',\n",
       " 'abort gopdebaâ',\n",
       " 'abort great',\n",
       " 'abort greatest',\n",
       " 'abort hell',\n",
       " 'abort httpstcoyzljablbq4',\n",
       " 'abort httptcogyjq13nw35',\n",
       " 'abort illeg',\n",
       " 'abort im',\n",
       " 'abort immor',\n",
       " 'abort isi',\n",
       " 'abort jebbush',\n",
       " 'abort keep',\n",
       " 'abort last',\n",
       " 'abort like',\n",
       " 'abort murder',\n",
       " 'abort must',\n",
       " 'abort never',\n",
       " 'abort new',\n",
       " 'abort none',\n",
       " 'abort nonsuperstar',\n",
       " 'abort nuhuh',\n",
       " 'abort oop',\n",
       " 'abort opinion',\n",
       " 'abort peopl',\n",
       " 'abort portion',\n",
       " 'abort privaci',\n",
       " 'abort problem',\n",
       " 'abort question',\n",
       " 'abort rape',\n",
       " 'abort record',\n",
       " 'abort right',\n",
       " 'abort scari',\n",
       " 'abort scott',\n",
       " 'abort serious',\n",
       " 'abort shouldnt',\n",
       " 'abort slaveri',\n",
       " 'abort stfu',\n",
       " 'abort talk',\n",
       " 'abort unborn',\n",
       " 'abort war',\n",
       " 'abort women',\n",
       " 'abort wtf',\n",
       " 'abort young',\n",
       " 'abort your',\n",
       " 'abortionismurd',\n",
       " 'abortionismurd plannedparenthood',\n",
       " 'abortionâ',\n",
       " 'abortionâ freak',\n",
       " 'abortus',\n",
       " 'abortus 2015',\n",
       " 'about',\n",
       " 'aboâ',\n",
       " 'abraham',\n",
       " 'abraham lincoln',\n",
       " 'abroad',\n",
       " 'abroad love',\n",
       " 'abs_tellthetal',\n",
       " 'abs_tellthetal your',\n",
       " 'absofuckinglut',\n",
       " 'absofuckinglut reducul',\n",
       " 'absolut',\n",
       " 'absolut author',\n",
       " 'absolut control',\n",
       " 'absolut disast',\n",
       " 'absolut disrespect',\n",
       " 'absolut domin',\n",
       " 'absolut fear',\n",
       " 'absolut gopdeb',\n",
       " 'absolut hilari',\n",
       " 'absolut mess',\n",
       " 'absolut need',\n",
       " 'absolut noth',\n",
       " 'absolut nut',\n",
       " 'absolut question',\n",
       " 'absolut refus',\n",
       " 'absolut ridicul',\n",
       " 'absolut sane',\n",
       " 'absolut terrifi',\n",
       " 'absolut unabl',\n",
       " 'absurd',\n",
       " 'absurd choic',\n",
       " 'absurd figur',\n",
       " 'absurd gopdeb',\n",
       " 'absurd statement',\n",
       " 'absurdwith',\n",
       " 'absurdwith shit',\n",
       " 'abt',\n",
       " 'abt abort',\n",
       " 'abt buy',\n",
       " 'abt candycrowley',\n",
       " 'abt crimin',\n",
       " 'abt crude',\n",
       " 'abt foreign',\n",
       " 'abt gopdeb',\n",
       " 'abt hes',\n",
       " 'abt immigr',\n",
       " 'abt liber',\n",
       " 'abt polit',\n",
       " 'abt poverti',\n",
       " 'abt remark',\n",
       " 'abt women',\n",
       " 'aburgeraday',\n",
       " 'aburgeraday balderdash',\n",
       " 'abus',\n",
       " 'abus asshol',\n",
       " 'abus power',\n",
       " 'abus system',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(X_train_counts,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)\n",
    "test_x = count_vect.transform(test['cleantxt'])\n",
    "test_x_array = test_x.toarray()\n",
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(test_x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8546132339235788"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[824,  29],\n",
       "       [127,  93]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions,labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('unibiwrong.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]!=test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 1:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','positive'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 0: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','negtive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('unibiright.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]==test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 0:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','negative'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 1: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','positive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW - UNI +  Intensified bi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "intbidf = pd.read_csv(\"intbi.csv\",encoding='ISO-8859-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intbidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for p in intbidf['intensified bi']:\n",
    "    count = 0\n",
    "    for text in train_x:\n",
    "        if p in text:\n",
    "            count += 1\n",
    "    dict[p] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disappoint fox', 131),\n",
       " ('great job', 19),\n",
       " ('ass gopdeb', 18),\n",
       " ('best line', 18),\n",
       " ('absolut fear', 17),\n",
       " ('straight outta', 16),\n",
       " ('good gopdeb', 15),\n",
       " ('biggest loser', 14),\n",
       " ('great joke', 14),\n",
       " ('better answer', 13)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sorted_dict = sorted_dict[:10]\n",
    "top_sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "biglist = []\n",
    "for i in train_x:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "           mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9656"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "#len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intbi_train_x=np.array([np.array(xi) for xi in biglist])\n",
    "intbi_train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intbi_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, 12533)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(intbi_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_x = np.concatenate((X_train_counts.toarray(), intbi_train_x), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, 12543)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for uni + Intensified bi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(c_train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)\n",
    "test_x = count_vect.transform(test['cleantxt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_array = test_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in test['cleantxt']:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intbi_test_x=np.array([np.array(xi) for xi in biglist])\n",
    "intbi_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine test data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test_x = np.concatenate((test_x_array, intbi_test_x), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(c_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8490214352283317"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[811,  42],\n",
       "       [120, 100]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions,labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('uniintbiwrong.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]!=test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 1:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','positive'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 0: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','negtive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('uniintbiright.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]==test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 0:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','negative'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 1: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','positive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW - UNI + Intensified uni "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "intunidf = pd.read_csv(\"intuni.csv\",encoding='ISO-8859-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intunidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for p in intunidf['intensified uni']:\n",
    "    count = 0\n",
    "    for text in train_x:\n",
    "        if p in text:\n",
    "            count += 1\n",
    "    dict[p] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ass', 307),\n",
       " ('great', 195),\n",
       " ('good', 193),\n",
       " ('best', 136),\n",
       " ('fuck', 118),\n",
       " ('better', 110),\n",
       " ('bad', 100),\n",
       " ('far', 85),\n",
       " ('total', 49),\n",
       " ('import', 43)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sorted_dict = sorted_dict[:10]\n",
    "top_sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in train_x:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intuni_train_x=np.array([np.array(xi) for xi in biglist])\n",
    "intuni_train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_x = np.concatenate((X_train_counts.toarray(), intuni_train_x), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for UNI + Intensified uni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(c_train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)\n",
    "test_x = count_vect.transform(test['cleantxt'])\n",
    "test_x_array = test_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in test['cleantxt']:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intuni_test_x=np.array([np.array(xi) for xi in biglist])\n",
    "intuni_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test_x = np.concatenate((test_x_array, intuni_test_x), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(c_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434296365330848"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[805,  48],\n",
       "       [120, 100]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions,labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW - UNI + Unitensified Bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbidf = pd.read_csv(\"unbi.csv\",encoding='ISO-8859-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for p in unbidf['unitensified bi']:\n",
    "    count = 0\n",
    "    for text in train_x:\n",
    "        if p in text:\n",
    "            count += 1\n",
    "    dict[p] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fair amp', 188),\n",
       " ('obvious tri', 135),\n",
       " ('legitim question', 63),\n",
       " ('realli like', 58),\n",
       " ('right gopdeb', 55),\n",
       " ('mean realdonaldtrump', 52),\n",
       " ('right mean', 51),\n",
       " ('right fight', 39),\n",
       " ('close statement', 29),\n",
       " ('right nobodi', 23)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sorted_dict = sorted_dict[:10]\n",
    "top_sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in train_x:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbi_train_x=np.array([np.array(xi) for xi in biglist])\n",
    "unbi_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_x = np.concatenate((X_train_counts.toarray(), unbi_train_x), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for UNI + Unitensified Bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(c_train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test_x = count_vect.transform(test['cleantxt'])\n",
    "test_x_array = test_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in test['cleantxt']:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbi_test_x=np.array([np.array(xi) for xi in biglist])\n",
    "unbi_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test_x = np.concatenate((test_x_array, unbi_test_x), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(c_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313140726933831"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[803,  50],\n",
       "       [131,  89]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions,labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW - UNI + Unitensified Uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ununidf = pd.read_csv(\"ununi.csv\",encoding='ISO-8859-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ununidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for p in ununidf['unintensified uni']:\n",
    "    count = 0\n",
    "    for text in train_x:\n",
    "        if p in text:\n",
    "            count += 1\n",
    "    dict[p] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('real', 1373),\n",
       " ('ok', 650),\n",
       " ('right', 388),\n",
       " ('fair', 259),\n",
       " ('realli', 259),\n",
       " ('big', 186),\n",
       " ('fun', 162),\n",
       " ('obvious', 162),\n",
       " ('mean', 137),\n",
       " ('liber', 100)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sorted_dict = sorted_dict[:10]\n",
    "top_sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in train_x:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ununi_train_x=np.array([np.array(xi) for xi in biglist])\n",
    "ununi_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9656"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "#len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_x = np.concatenate((X_train_counts.toarray(), ununi_train_x), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for UNI + Unitensified Uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(c_train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test_x = count_vect.transform(test['cleantxt'])\n",
    "test_x_array = test_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = []\n",
    "for i in test['cleantxt']:\n",
    "    mylist =[]\n",
    "    for a,b in top_sorted_dict:\n",
    "        if a in i:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "      \n",
    "    biglist.append(mylist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biglist)\n",
    "len(biglist[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ununi_test_x=np.array([np.array(xi) for xi in biglist])\n",
    "ununi_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test_x = np.concatenate((test_x_array, ununi_test_x), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(c_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285181733457595"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[800,  53],\n",
       "       [131,  89]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions,labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNI + BI + INTENSIFIER + UNINTENSIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Idf's + unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df=1,stop_words='english',max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tfidf = tf.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tfidf_array = train_x_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_tfidf_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['adult', 'bring', 'gopdeb', 'megynkelli', 'picturesshould', 'pose',\n",
       "        'rt', 'rwsurfergirl'], dtype='<U40')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.inverse_transform(train_x_tfidf_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Idf's + unigram + bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_bi = TfidfVectorizer(ngram_range=(1,2),min_df=1,stop_words='english',max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.array(['blah blah','drink game','exact like','lmfao'])\n",
    "#s = pd.Series(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featfidf = tf_bi.fit_transform(s)\n",
    "#featfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tfidf_bi = tf_bi.fit_transform(train_x)\n",
    "train_x_tfidf_array_bi = train_x_tfidf_bi.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_tfidf_array_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_tfidf_array_bi[0]\n",
    "len(train_x_tfidf_array_bi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '10 men',\n",
       " '10 million',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '14',\n",
       " '14th',\n",
       " '14th amend',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '19',\n",
       " '1st',\n",
       " '1st debat',\n",
       " '1st gopdeb',\n",
       " '20',\n",
       " '2012',\n",
       " '2013',\n",
       " '2015',\n",
       " '2015 gopdeb',\n",
       " '2016',\n",
       " '2016 gopdeb',\n",
       " '2016 presidenti',\n",
       " '2016elect',\n",
       " '21st',\n",
       " '21st centuri',\n",
       " '22aday',\n",
       " '22aday empti',\n",
       " '2nd',\n",
       " '2nd string',\n",
       " '30',\n",
       " '30 yrs',\n",
       " '32',\n",
       " '3rd',\n",
       " '3rd parti',\n",
       " '40',\n",
       " '44',\n",
       " '4th',\n",
       " '4th amend',\n",
       " '50',\n",
       " '50th',\n",
       " '50th anniversari',\n",
       " '5th',\n",
       " '70',\n",
       " '70 year',\n",
       " '700',\n",
       " '700 law',\n",
       " '90',\n",
       " '90 day',\n",
       " '911',\n",
       " '_hankrearden',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'abc cbs',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abort',\n",
       " 'abort ban',\n",
       " 'abort dont',\n",
       " 'abort gopdeb',\n",
       " 'abort question',\n",
       " 'abort right',\n",
       " 'abs_tellthetal',\n",
       " 'abs_tellthetal success',\n",
       " 'absolut',\n",
       " 'absolut fear',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accident eat',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accus',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'act love',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actual gopdeb',\n",
       " 'actual like',\n",
       " 'actual said',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'address',\n",
       " 'admin',\n",
       " 'admin gopdeb',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'admit buy',\n",
       " 'admit republican',\n",
       " 'admit want',\n",
       " 'adult',\n",
       " 'adult picturesshould',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advantag law',\n",
       " 'advantag skirt',\n",
       " 'advic',\n",
       " 'advic gop',\n",
       " 'advis',\n",
       " 'advoc',\n",
       " 'afford',\n",
       " 'afforâ',\n",
       " 'afraid',\n",
       " 'aftermath',\n",
       " 'ag_conserv',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggress',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agre gopdeb',\n",
       " 'agre teletubbi',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'ahead race',\n",
       " 'aid',\n",
       " 'aid convict',\n",
       " 'ainf',\n",
       " 'ainf tlot',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'air time',\n",
       " 'airtim',\n",
       " 'aka',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alexandraheus',\n",
       " 'alien',\n",
       " 'alien gopdeb',\n",
       " 'aliv',\n",
       " 'allenwestrepub',\n",
       " 'allenwestrepub dear',\n",
       " 'allow',\n",
       " 'alon',\n",
       " 'alreadi',\n",
       " 'alreadi rule',\n",
       " 'alway',\n",
       " 'alway tell',\n",
       " 'amaraconda',\n",
       " 'amaz',\n",
       " 'ambush',\n",
       " 'ambush gopdeb',\n",
       " 'amen',\n",
       " 'amen gopdeb',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'america american',\n",
       " 'america christian',\n",
       " 'america gopdeb',\n",
       " 'america great',\n",
       " 'america need',\n",
       " 'america today',\n",
       " 'american',\n",
       " 'american citizen',\n",
       " 'american dream',\n",
       " 'american peopl',\n",
       " 'amp',\n",
       " 'amp anoint',\n",
       " 'amp balanc',\n",
       " 'amp ben',\n",
       " 'amp billhemm',\n",
       " 'amp car',\n",
       " 'amp china',\n",
       " 'amp chris',\n",
       " 'amp dc',\n",
       " 'amp drudg',\n",
       " 'amp foxnew',\n",
       " 'amp gop',\n",
       " 'amp gopdeb',\n",
       " 'amp got',\n",
       " 'amp love',\n",
       " 'amp marco',\n",
       " 'amp mexican',\n",
       " 'amp rest',\n",
       " 'amp sexual',\n",
       " 'amp trump',\n",
       " 'amymek',\n",
       " 'analysi',\n",
       " 'anchor',\n",
       " 'andor',\n",
       " 'andreatantaro',\n",
       " 'anger',\n",
       " 'angri',\n",
       " 'anim',\n",
       " 'ann',\n",
       " 'anncoult',\n",
       " 'annebayefski',\n",
       " 'annemariew',\n",
       " 'annemariew poetinpoevill',\n",
       " 'anniversari',\n",
       " 'anniversari vote',\n",
       " 'annleari',\n",
       " 'announc',\n",
       " 'anoint',\n",
       " 'anoint man',\n",
       " 'anoth',\n",
       " 'anoth gopdeb',\n",
       " 'anoth green',\n",
       " 'answer',\n",
       " 'answer direct',\n",
       " 'answer gay',\n",
       " 'answer given',\n",
       " 'answer gopdeb',\n",
       " 'answer question',\n",
       " 'anthonycumia',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anymor gopdeb',\n",
       " 'anyon',\n",
       " 'anyon els',\n",
       " 'anyon gop',\n",
       " 'anyon realli',\n",
       " 'anyon think',\n",
       " 'anyth',\n",
       " 'anyth help',\n",
       " 'apart',\n",
       " 'apathycas',\n",
       " 'apathycas trump',\n",
       " 'apolog',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'appl martini',\n",
       " 'applaud',\n",
       " 'applaus',\n",
       " 'appli',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'approv',\n",
       " 'aprx',\n",
       " 'aprx 700',\n",
       " 'area',\n",
       " 'area larger',\n",
       " 'arena',\n",
       " 'arena gopdeb',\n",
       " 'arent',\n",
       " 'arent cut',\n",
       " 'arent real',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'argument gop',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'arrog',\n",
       " 'arrogantsnarki',\n",
       " 'arrogantsnarki gopdeb',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'ask',\n",
       " 'ask candid',\n",
       " 'ask god',\n",
       " 'ask gopdeb',\n",
       " 'ask politican',\n",
       " 'ask question',\n",
       " 'ask real',\n",
       " 'ask realdonaldtrump',\n",
       " 'ask tedcruz',\n",
       " 'ask tough',\n",
       " 'ask trump',\n",
       " 'ask wassermanschultz',\n",
       " 'ass',\n",
       " 'ass gopdeb',\n",
       " 'ass serv',\n",
       " 'assassin',\n",
       " 'assassin attempt',\n",
       " 'assclown',\n",
       " 'assess',\n",
       " 'asshat',\n",
       " 'asshol',\n",
       " 'asshol gopdeb',\n",
       " 'assimil',\n",
       " 'assimil invas',\n",
       " 'assum',\n",
       " 'atlant',\n",
       " 'atlant citi',\n",
       " 'atom',\n",
       " 'atom bomb',\n",
       " 'attack',\n",
       " 'attack candid',\n",
       " 'attack realdonaldtrump',\n",
       " 'attack trump',\n",
       " 'attempt',\n",
       " 'attempt gop',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'audienc',\n",
       " 'audienc blacklivematt',\n",
       " 'audienc gopdeb',\n",
       " 'averykayla',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awak',\n",
       " 'awak watch',\n",
       " 'awar',\n",
       " 'awar hes',\n",
       " 'award',\n",
       " 'away',\n",
       " 'away gopdeb',\n",
       " 'away gopdebâ',\n",
       " 'away sexism',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'aâ',\n",
       " 'b140_tweet',\n",
       " 'babi',\n",
       " 'babi gopdeb',\n",
       " 'bad',\n",
       " 'bad gopdeb',\n",
       " 'bad recov',\n",
       " 'badassteachersa',\n",
       " 'baffl',\n",
       " 'baier',\n",
       " 'balanc',\n",
       " 'balanc debat',\n",
       " 'balanc msn',\n",
       " 'balanc ðºð',\n",
       " 'balconi',\n",
       " 'balconi sound',\n",
       " 'ball',\n",
       " 'baltimor',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'band togeth',\n",
       " 'bandwagon',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'bankrupt realli',\n",
       " 'bankruptci',\n",
       " 'bankruptci advantag',\n",
       " 'bankruptci gopdeb',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barack obama',\n",
       " 'barbarabox',\n",
       " 'bare',\n",
       " 'bare let',\n",
       " 'bare stay',\n",
       " 'barf',\n",
       " 'base',\n",
       " 'bash',\n",
       " 'bash pbo',\n",
       " 'basi',\n",
       " 'basi fact',\n",
       " 'basic',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'batsask',\n",
       " 'batsask gopdeb',\n",
       " 'battl',\n",
       " 'bc',\n",
       " 'bc2dc16',\n",
       " 'beat',\n",
       " 'beat jamaica',\n",
       " 'beauti',\n",
       " 'becam',\n",
       " 'becam nightmar',\n",
       " 'becom',\n",
       " 'becom presid',\n",
       " 'becom republican',\n",
       " 'bed',\n",
       " 'beer',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'begin end',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'believ gopdeb',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'ben',\n",
       " 'ben carson',\n",
       " 'bencarson',\n",
       " 'bencarson gopdeb',\n",
       " 'bencarson2016',\n",
       " 'bencarson2016 gopdeb',\n",
       " 'benefit',\n",
       " 'benghazi',\n",
       " 'benghazi gopdeb',\n",
       " 'benshapiro',\n",
       " 'berni',\n",
       " 'berni sander',\n",
       " 'bernie2016',\n",
       " 'berniesand',\n",
       " 'berniesand gopdeb',\n",
       " 'best',\n",
       " 'best charact',\n",
       " 'best close',\n",
       " 'best gopdeb',\n",
       " 'best line',\n",
       " 'best perform',\n",
       " 'best thing',\n",
       " 'bet',\n",
       " 'bethbehr',\n",
       " 'bethbehr classi',\n",
       " 'better',\n",
       " 'better answer',\n",
       " 'better balanc',\n",
       " 'better gopdeb',\n",
       " 'better job',\n",
       " 'better plan',\n",
       " 'bettybow',\n",
       " 'bettyfckinwhit',\n",
       " 'bettyfckinwhit answer',\n",
       " 'bettyfckinwhit donald',\n",
       " 'bettyfckinwhit mani',\n",
       " 'bettyfckinwhit repeal',\n",
       " 'bias',\n",
       " 'bias gopdeb',\n",
       " 'biasedgirl',\n",
       " 'bibl',\n",
       " 'biff',\n",
       " 'biff futur',\n",
       " 'big',\n",
       " 'big boy',\n",
       " 'big deal',\n",
       " 'big loser',\n",
       " 'big problem',\n",
       " 'big winner',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'biggest loser',\n",
       " 'biggest winner',\n",
       " 'bigotri',\n",
       " 'billhemm',\n",
       " 'billhemm arrogantsnarki',\n",
       " 'billion',\n",
       " 'billionair',\n",
       " 'billmah',\n",
       " 'bimbo',\n",
       " 'bimbo gopdeb',\n",
       " 'bingo',\n",
       " 'bipartisan',\n",
       " 'birth',\n",
       " 'birth control',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchasspoliâ',\n",
       " 'bite',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'black gopdeb',\n",
       " 'black live',\n",
       " 'black man',\n",
       " 'black peopl',\n",
       " 'black vote',\n",
       " 'blackliveematt',\n",
       " 'blackliveematt gopdeb',\n",
       " 'blacklivematt',\n",
       " 'blacklivematt gopdebatâ',\n",
       " 'blacklivesdontmatt',\n",
       " 'blacklivesdontmatt bash',\n",
       " 'blacklivesmatt',\n",
       " 'blacklivesmatt cop',\n",
       " 'blacklivesmatt gopdeb',\n",
       " 'blacklivesmatt httptcojc9jhrrcpw',\n",
       " 'blacklivesmatt question',\n",
       " 'blah',\n",
       " 'blah blah',\n",
       " 'blame',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'block',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'bnrdebat',\n",
       " 'bob',\n",
       " 'bob big',\n",
       " 'bobcesca_go',\n",
       " 'bodi',\n",
       " 'bodi amp',\n",
       " 'bodi gopdeb',\n",
       " 'bodi govern',\n",
       " 'bodi whererwomen',\n",
       " 'bold',\n",
       " 'bomb',\n",
       " 'bomb trump',\n",
       " 'boo',\n",
       " 'boo noamnesti',\n",
       " 'book',\n",
       " 'book yep',\n",
       " 'boom',\n",
       " 'boom rednationrais',\n",
       " 'booz',\n",
       " 'bor',\n",
       " 'bor httpstcolklffn2lfi',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'bother',\n",
       " 'bought',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'boy haircut',\n",
       " 'boy social',\n",
       " 'boycott',\n",
       " 'brag',\n",
       " 'brag fuck',\n",
       " 'brain',\n",
       " 'brain best',\n",
       " 'brain littl',\n",
       " 'branch',\n",
       " 'break',\n",
       " 'break brian',\n",
       " 'break gopdeb',\n",
       " 'break news',\n",
       " 'break thing',\n",
       " 'break thingsmik',\n",
       " 'bret',\n",
       " 'bretbaier',\n",
       " 'brian',\n",
       " 'brian william',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bring god',\n",
       " 'bring gopdeb',\n",
       " 'brios82',\n",
       " 'brithum',\n",
       " 'broadcast',\n",
       " 'brock_a_r',\n",
       " 'brock_a_r wonder',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brother gopdeb',\n",
       " 'brother way',\n",
       " 'brotherhood',\n",
       " 'brotherhood america',\n",
       " 'brought',\n",
       " 'brought byâ',\n",
       " 'brought gopdeb',\n",
       " 'bruh',\n",
       " 'brutal',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'bucksexton',\n",
       " 'budget',\n",
       " 'budget budget',\n",
       " 'budget multipl',\n",
       " 'budget talk',\n",
       " 'buffoon',\n",
       " 'build',\n",
       " 'build wall',\n",
       " 'bull',\n",
       " 'bulli',\n",
       " 'bullshit',\n",
       " 'bump',\n",
       " 'bump kasich',\n",
       " 'bunch',\n",
       " 'bunch loser',\n",
       " 'burn',\n",
       " 'bush',\n",
       " 'bush admin',\n",
       " 'bush fuck',\n",
       " 'bush gopdeb',\n",
       " 'bush know',\n",
       " 'bush lie',\n",
       " 'bush obama',\n",
       " 'bush record',\n",
       " 'bush remind',\n",
       " 'bush rubio',\n",
       " 'bush swear',\n",
       " 'bush threat',\n",
       " 'bush trump2016',\n",
       " 'busi',\n",
       " 'busi gopdeb',\n",
       " 'busi iran',\n",
       " 'busi went',\n",
       " 'bust',\n",
       " 'butt',\n",
       " 'buy',\n",
       " 'buy influenc',\n",
       " 'buy politician',\n",
       " 'bye',\n",
       " 'byâ',\n",
       " 'byâ straight',\n",
       " 'bâ',\n",
       " 'cabinet',\n",
       " 'cabl',\n",
       " 'cage',\n",
       " 'cairo',\n",
       " 'cairo rail',\n",
       " 'calamari',\n",
       " 'calamari debat',\n",
       " 'calm',\n",
       " 'calm ðºð',\n",
       " 'cam',\n",
       " 'cam hand',\n",
       " 'came',\n",
       " 'came close',\n",
       " 'came war',\n",
       " 'camera',\n",
       " 'campaign',\n",
       " 'campaign financ',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancel primari',\n",
       " 'candi',\n",
       " 'candid',\n",
       " 'candid actual',\n",
       " 'candid choic',\n",
       " 'candid christianbrotherhood',\n",
       " 'candid dont',\n",
       " 'candid given',\n",
       " 'candid gopdeb',\n",
       " 'candid ive',\n",
       " 'candid jeb',\n",
       " 'candid let',\n",
       " 'candid like',\n",
       " 'candid make',\n",
       " 'candid mention',\n",
       " 'candid night',\n",
       " 'candid order',\n",
       " 'candid plan',\n",
       " 'candid presid',\n",
       " 'candid receiv',\n",
       " 'candid said',\n",
       " 'candid say',\n",
       " 'candid stage',\n",
       " 'candid talk',\n",
       " 'candid think',\n",
       " 'candid trip',\n",
       " 'candidaci',\n",
       " 'candycrowley',\n",
       " 'canttrustabush',\n",
       " 'canttrustabush morningjo',\n",
       " 'canât',\n",
       " 'capit',\n",
       " 'car',\n",
       " 'car fiorina',\n",
       " 'card',\n",
       " 'care',\n",
       " 'care gopdeb',\n",
       " 'career',\n",
       " 'career politician',\n",
       " 'carly2016',\n",
       " 'carly2016 gopdeb',\n",
       " 'carlyfiorina',\n",
       " 'carlyfiorina amp',\n",
       " 'carlyfiorina gopdeb',\n",
       " 'carlyð',\n",
       " 'carlyð carlyð',\n",
       " 'carolhello1',\n",
       " 'carri',\n",
       " 'carri water',\n",
       " 'carrier',\n",
       " 'carrier decad',\n",
       " 'carson',\n",
       " 'carson amp',\n",
       " 'carson carri',\n",
       " 'carson carson',\n",
       " 'carson dammit',\n",
       " 'carson gopdeb',\n",
       " 'carson remark',\n",
       " 'carson say',\n",
       " 'carson solidifi',\n",
       " 'carson talk',\n",
       " 'carson ðºð',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'case past',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'cbs',\n",
       " 'cbsmiami',\n",
       " 'cbsmiami gopdeb',\n",
       " 'ccot',\n",
       " 'ccot gopdeb',\n",
       " 'ccot pjnet',\n",
       " 'ccot tcot',\n",
       " 'ccot ycot',\n",
       " 'cdc',\n",
       " 'cdm',\n",
       " 'cdm rwsurfergirl',\n",
       " 'cement',\n",
       " 'cement gopdeb',\n",
       " 'cenkuygur',\n",
       " 'cenkuygur cancel',\n",
       " 'censor',\n",
       " 'center',\n",
       " 'center gopdeb',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'ceo',\n",
       " 'ceremoni',\n",
       " 'ceremoni gopdeb',\n",
       " 'certain',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'champion',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'chang gopdeb',\n",
       " 'chang gun',\n",
       " 'chang iota',\n",
       " 'chang mind',\n",
       " 'channel',\n",
       " 'chant',\n",
       " 'charact',\n",
       " 'charact gopdeb',\n",
       " 'charg',\n",
       " 'charm',\n",
       " 'charm longer',\n",
       " 'chase',\n",
       " 'check',\n",
       " 'cheer',\n",
       " 'cherri',\n",
       " 'cherri pick',\n",
       " 'child',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'children away',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'china know',\n",
       " 'chines',\n",
       " 'chines hack',\n",
       " 'choic',\n",
       " 'choic chang',\n",
       " 'choic women',\n",
       " 'choos',\n",
       " 'chris',\n",
       " 'chris christi',\n",
       " 'chris wallac',\n",
       " 'chrischristi',\n",
       " 'chrischristi gopdeb',\n",
       " 'chrischristi hug',\n",
       " 'chrisjzullo',\n",
       " 'christ',\n",
       " 'christi',\n",
       " 'christi bob',\n",
       " 'christi donut',\n",
       " 'christi gopdeb',\n",
       " 'christi want',\n",
       " 'christian',\n",
       " 'christian brotherhood',\n",
       " 'christianbrotherhood',\n",
       " 'christianbrotherhood gopdeb',\n",
       " 'chriswallac',\n",
       " 'chucknelli',\n",
       " 'church',\n",
       " 'church state',\n",
       " 'circl',\n",
       " 'circus',\n",
       " 'citi',\n",
       " 'citizen',\n",
       " 'citizenship',\n",
       " 'civil',\n",
       " 'civil right',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classi',\n",
       " 'classi gopdeb',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clear winner',\n",
       " 'cleveland',\n",
       " 'climat',\n",
       " 'climat chang',\n",
       " 'climatechang',\n",
       " 'clinton',\n",
       " 'clinton email',\n",
       " 'clinton gopdeb',\n",
       " 'clip',\n",
       " 'clip gopdeb',\n",
       " 'clip irand',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'close argument',\n",
       " 'close statement',\n",
       " 'cloth',\n",
       " 'cloudypiano',\n",
       " 'cloudypiano im',\n",
       " 'clown',\n",
       " 'clown car',\n",
       " 'clown feelthebern',\n",
       " 'clown gopdeb',\n",
       " 'clown trump',\n",
       " 'clowncar',\n",
       " 'clue',\n",
       " 'clue issuesâ',\n",
       " 'clueless',\n",
       " 'clueless isi',\n",
       " 'cmon',\n",
       " 'cnn',\n",
       " 'cnn gopdeb',\n",
       " 'cnn msnbc',\n",
       " 'code',\n",
       " 'code control',\n",
       " 'coincid',\n",
       " 'cold',\n",
       " 'collaps',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'color',\n",
       " 'color gopdeb',\n",
       " 'combin',\n",
       " 'combov',\n",
       " 'combov httptcois9gyb7p31',\n",
       " 'come',\n",
       " 'come gopdeb',\n",
       " 'come syria',\n",
       " 'come ðºð',\n",
       " 'comeback',\n",
       " 'comedi',\n",
       " 'comedi laugh',\n",
       " 'comedian',\n",
       " 'comfort',\n",
       " 'command',\n",
       " 'comment',\n",
       " 'comment earn',\n",
       " 'comment gopdeb',\n",
       " 'comment women',\n",
       " 'commentari',\n",
       " 'commerci',\n",
       " 'commerci break',\n",
       " 'commerci fox',\n",
       " 'commerci gopdeb',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'common core',\n",
       " 'common sens',\n",
       " 'commoncor',\n",
       " 'commoncor pleas',\n",
       " 'communiti',\n",
       " 'compani',\n",
       " 'compar',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'complain',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complex slimi',\n",
       " 'compton',\n",
       " 'compton commerci',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concern trump',\n",
       " 'conclus',\n",
       " 'condescend',\n",
       " 'conduct',\n",
       " 'conduct fair',\n",
       " 'conflict',\n",
       " 'confus',\n",
       " 'congrat',\n",
       " 'congratul',\n",
       " 'congress',\n",
       " 'congress boom',\n",
       " 'congress gopdeb',\n",
       " 'congress vote',\n",
       " 'consensus',\n",
       " 'consequ',\n",
       " 'consequ gopdeb',\n",
       " 'conserv',\n",
       " 'conserv gopdeb',\n",
       " 'conserv valu',\n",
       " 'conserv woman',\n",
       " 'conservat',\n",
       " 'consid',\n",
       " 'consid 10',\n",
       " 'consist',\n",
       " 'conspiraci',\n",
       " 'constitut',\n",
       " 'constitut right',\n",
       " 'construct',\n",
       " 'construct theyr',\n",
       " 'contend',\n",
       " 'contest',\n",
       " 'continu',\n",
       " 'contrast',\n",
       " 'control',\n",
       " 'control debat',\n",
       " 'control women',\n",
       " 'conveni',\n",
       " 'convers',\n",
       " 'convict',\n",
       " 'convict feloni',\n",
       " 'convinc',\n",
       " 'convinc year',\n",
       " 'cooki',\n",
       " 'cool',\n",
       " 'cooper',\n",
       " 'cop',\n",
       " 'cop involv',\n",
       " 'cop kill',\n",
       " 'core',\n",
       " 'corpor',\n",
       " 'correct',\n",
       " 'correct gopdeb',\n",
       " 'correct war',\n",
       " 'correctrecord',\n",
       " 'corrupt',\n",
       " 'cost',\n",
       " 'couldv',\n",
       " 'count',\n",
       " 'countri',\n",
       " 'countri commoncor',\n",
       " 'countri gopdeb',\n",
       " 'countri need',\n",
       " 'countri ðºð',\n",
       " 'coupl',\n",
       " 'cours',\n",
       " 'cours gopdeb',\n",
       " 'cover',\n",
       " 'coverag',\n",
       " 'coverag gopdeb',\n",
       " 'crack',\n",
       " 'crap',\n",
       " 'crappi',\n",
       " 'crash',\n",
       " 'crash economi',\n",
       " 'crazi',\n",
       " 'creat',\n",
       " 'creat cultur',\n",
       " 'creat job',\n",
       " 'credibl',\n",
       " 'credit',\n",
       " 'creepi',\n",
       " 'cri',\n",
       " 'cri gopdeb',\n",
       " 'crimin',\n",
       " 'critic',\n",
       " 'crook',\n",
       " 'crook koch',\n",
       " 'crowd',\n",
       " 'crowley',\n",
       " 'crush',\n",
       " 'cruz',\n",
       " 'cruz carson',\n",
       " 'cruz gopdeb',\n",
       " 'cruz look',\n",
       " 'cruz mutant',\n",
       " 'cruz rubio',\n",
       " 'cruz scriptur',\n",
       " 'cruz trump',\n",
       " 'cruz word',\n",
       " 'cruzcrew',\n",
       " 'cruzcrew gopdeb',\n",
       " 'cuckserv',\n",
       " 'cultur',\n",
       " 'cultur life',\n",
       " 'cur',\n",
       " 'cur hair',\n",
       " 'cure',\n",
       " 'current',\n",
       " 'cut',\n",
       " 'cut uw',\n",
       " 'cute',\n",
       " 'cute chris',\n",
       " 'cuz',\n",
       " 'câ',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'dad mailman',\n",
       " 'daili',\n",
       " 'damag',\n",
       " 'damienfahey',\n",
       " 'dammit',\n",
       " 'dammit man',\n",
       " 'damn',\n",
       " 'damn christian',\n",
       " 'damn dwstweet',\n",
       " 'damn megyn',\n",
       " 'danc',\n",
       " 'danger',\n",
       " 'danmoore755',\n",
       " 'danscavino',\n",
       " 'danscavino megynkelli',\n",
       " 'dare',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'daveweigel',\n",
       " 'day',\n",
       " 'day gopdeb',\n",
       " 'dc',\n",
       " 'dc half',\n",
       " 'dc media',\n",
       " ...]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_bi.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_bi.get_feature_names())\n",
    "#type(tf_bi.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('bigramfeature.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"features\"])\n",
    "    for feature in tf_bi.get_feature_names():\n",
    "        writer.writerow([feature])\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['adult', 'adult picturesshould', 'bring', 'bring gopdeb', 'gopdeb',\n",
       "        'gopdeb gopdeb', 'megynkelli', 'megynkelli pose', 'picturesshould',\n",
       "        'picturesshould bring', 'pose', 'pose adult', 'rt',\n",
       "        'rt rwsurfergirl', 'rwsurfergirl', 'rwsurfergirl megynkelli'],\n",
       "       dtype='<U32')]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_bi.inverse_transform(train_x_tfidf_array_bi[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes for bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(intbi_train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)\n",
    "test_x = count_vect.transform(test['cleantxt'])\n",
    "test_x_array = test_x.toarray()\n",
    "test_y = le.transform(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(test_x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848089468779124"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/2146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_tfidf_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8dfe0524c9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_tfidf_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_tfidf_array' is not defined"
     ]
    }
   ],
   "source": [
    "mnb.fit(train_x_tfidf_array,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)\n",
    "test_x_tfidf = tf.transform(test['cleantxt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_tfidf_array = test_x_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = le.transform(test['sentiment']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 5000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_tfidf_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(test_x_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1787"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327120223671948"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/2146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes tf-idf + unigram + bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(train_x_tfidf_array_bi,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#prepare test data\n",
    "test['cleantxt'] = test['text'].apply(CleanText)\n",
    "test['cleantxt'] = test['cleantxt'].apply(removeStopWords)\n",
    "test['cleantxt'] = test['cleantxt'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_tfidf_bi = tf_bi.transform(test['cleantxt'])\n",
    "test_x_tfidf_array = test_x_tfidf_bi.toarray()\n",
    "test_y = le.transform(test['sentiment']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146,)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 5000)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_tfidf_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(test_x_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146,)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438956197576887"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/2146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GOPDebate had more action than the Manny vs Mayweather fight 0    1\n",
      "Love how Rubio said the election is not about resumes, but ideas for the future and a high tech future. #GOPDebates 0    1\n",
      "My response when @megynkelly tried to call @realDonaldTrump a sexist: \"CAN'T STUMP THE TRUMP!\" #GOPDebate 0    1\n",
      "RT @RWSurferGirl: Ask Trump a legitimate question. Look at Wallace's face when Trump nails it. ðºð¸ #GOPDebate  #GOPDebates 1    0\n",
      "RT @4BillLewis: #Facebook &amp; #Twitter made #GOPDebate interesting #jebbush #realdonaldtrump #marcorubio #scottwalker #JohnKasich #realbencarâ¦ 0    1\n",
      "RT @TheTexasPhoenix: He was on fire! .@GovernorPerry's \"On Fire\" Debate Performance: https://t.co/0A1w02w7SZ #GOPDebate #Perry2016 0    1\n",
      "#MarcoRubio speaks from a true American position. He's not perfect, but trying hard, giving it his very best  #FOXNEWSDEBATE #GOPDebates 0    1\n",
      "#FoxNews was the big winner at #GOPDebate. No way future viewership was not the objective. Surely already said. 0    1\n",
      "RT @CarlyFiorina: Talked with @ijreview about my pre-debate ritual. I take Solitaire very seriously. https://t.co/O7UJL56NM7 #GOPDebate #Caâ¦ 0    1\n",
      "Ben, I love ya man. I think it went more like @realDonaldTrump nailed them for thinking he isn't, wasn't. #GOPDebate https://t.co/nuCZHpHlvX 0    1\n",
      "RT @Sanddragger: #TrumpBashing at it's finest. #MegynKelly #MegynKellyDebateQuestions #GOPDebate https://t.co/3vyUKSNrWE 0    1\n"
     ]
    }
   ],
   "source": [
    "# an example to see the first 100\n",
    "for i in range (100):\n",
    "    if predictions[i]!=test_y[i]:\n",
    "        print(test.iloc[i].text,predictions[i],'  ' , test_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write into csv\n",
    "with open('wrong.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"text\",\"prediction\", \"sentiment\"])\n",
    "    for i in range (len(predictions)):\n",
    "        if predictions[i]!=test_y[i]:\n",
    "            if predictions[i] == 0 and test_y[i] == 1:\n",
    "                writer.writerow([str(test.iloc[i].text), 'negtive','positive'])\n",
    "            elif  predictions[i] == 1 and test_y[i] == 0: \n",
    "                writer.writerow([str(test.iloc[i].text), 'positive','negtive'])\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(train_x_tfidf_array,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157637189793778"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(train_x_tfidf_array,train_y) # running it on the train set itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858807082945014"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(test_x_tfidf_array,test_y) # running it on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression + unigram + bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snakes/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(train_x_tfidf_array_bi,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9149481533263427"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(train_x_tfidf_array_bi,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560111835973905"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(test_x_tfidf_array,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1.0,degree=1,kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x_tfidf_array,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_x_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predicted)):\n",
    "    if predicted[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583410997204101"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/2146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM + unigram + bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1.0,degree=1,kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x_tfidf_array_bi,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_x_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in range (len(predicted)):\n",
    "    if predicted[i]==test_y[i]:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8616029822926374"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/2146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
